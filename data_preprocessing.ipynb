{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet:\n",
    "    def __init__(self, data, faceId, label, normal):\n",
    "        assert(data.shape[0] == faceId.shape[0] == label.shape[0] == normal.shape[0])\n",
    "        self.contents = {\n",
    "            'data': data,\n",
    "            'faceId': faceId,\n",
    "            'label': label,\n",
    "            'normal': normal\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return self.contents['data'].shape[0]\n",
    "    def __getitem__(self, args):\n",
    "        if isinstance(args, str):\n",
    "            return self.contents[args]\n",
    "        if isinstance(args, list) or isinstance(args, slice) or isinstance(args, np.ndarray):\n",
    "            return MyDataSet(\n",
    "                self.contents['data'][args],\n",
    "                self.contents['faceId'][args],\n",
    "                self.contents['label'][args],\n",
    "                self.contents['normal'][args]\n",
    "            )\n",
    "    def __add__(self, other):\n",
    "        return MyDataSet.merge([self, other])\n",
    "    def __repr__(self):\n",
    "        string = f'<DataSet of {len(self)} records with {len(np.unique(self.contents[\"label\"]))} labels>'\n",
    "        return string\n",
    "    \n",
    "    def from_h5_file(file):\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            args = f['data'][:], f['faceId'][:], f['label'][:], f['normal'][:]\n",
    "        return MyDataSet(*args)\n",
    "    def from_h5_files(files):\n",
    "        return MyDataSet.merge([MyDataSet.from_h5_file(file) for file in files])\n",
    "    def to_h5_file(self, file, max_size = None):\n",
    "        if file[-3:] == '.h5':\n",
    "            file = file[:-3]\n",
    "        if not max_size or len(self) <= max_size:\n",
    "            with h5py.File(file + '.h5', 'w') as f:\n",
    "                f.create_dataset('data', data = self.contents['data'])\n",
    "                f.create_dataset('faceId', data = self.contents['faceId'])\n",
    "                f.create_dataset('label', data = self.contents['label'])\n",
    "                f.create_dataset('normal', data = self.contents['normal'])\n",
    "        else:\n",
    "            i = 0\n",
    "            while max_size * (i + 1) < len(self):\n",
    "                with h5py.File(file + str(i) + '.h5', 'w') as f:\n",
    "                    contents = self[i * max_size : (i + 1) * max_size]\n",
    "                    f.create_dataset('data', data = contents['data'])\n",
    "                    f.create_dataset('faceId', data = contents['faceId'])\n",
    "                    f.create_dataset('label', data = contents['label'])\n",
    "                    f.create_dataset('normal', data = contents['normal'])\n",
    "                i = i + 1\n",
    "            with h5py.File(file + str(i) + '.h5', 'w') as f:\n",
    "                contents = self[i * max_size :]\n",
    "                f.create_dataset('data', data = contents['data'])\n",
    "                f.create_dataset('faceId', data = contents['faceId'])\n",
    "                f.create_dataset('label', data = contents['label'])\n",
    "                f.create_dataset('normal', data = contents['normal'])\n",
    "    \n",
    "    def count(self, sort = None):\n",
    "        cnt = zip(*np.unique(self.contents['label'], return_counts = True))\n",
    "        if not sort:\n",
    "            return sorted(cnt, key = lambda x: x[0])\n",
    "        if sort == 'asc':\n",
    "            return sorted(cnt, key = lambda x: x[1])\n",
    "        elif sort == 'desc':\n",
    "            return sorted(cnt, key = lambda x: -x[1])\n",
    "        raise Exception('sort argument should be asc or desc')\n",
    "    def summary(self):\n",
    "        print(f'Num of records: {len(self)}\\t\\tNum of unique labels: {len(np.unique(self.contents[\"label\"]))}')\n",
    "        print(f'Unique labels and their frequencies:')\n",
    "        print(*self.count(sort = 'desc'))\n",
    "        \n",
    "    def merge(datasets):\n",
    "        arg_list = [[ds.contents[w] for ds in datasets] for w in ['data','faceId','label','normal']]\n",
    "        args = [np.concatenate(arg) for arg in arg_list]\n",
    "        return MyDataSet(*args)\n",
    "    def duplicate(self):\n",
    "        return MyDataSet(*[v.copy() for v in self.contents.values()])\n",
    "    def filter(self, label):\n",
    "        return self[np.isin(self.contents['label'], label).reshape(-1)]\n",
    "    def relabel(self, rename_dict):\n",
    "        # {old: new}\n",
    "        new_label = self.contents['label'].copy()\n",
    "        for old, new in rename_dict.items():\n",
    "            new_label[self.contents['label'] == old] = new\n",
    "        return MyDataSet(\n",
    "            self.contents['data'], self.contents['faceId'], new_label, self.contents['normal']\n",
    "        )\n",
    "    def remove(self, args):\n",
    "        if isinstance(args[0][0], bool):\n",
    "            return self[[not p for p in args[0]]]\n",
    "        return self[[not p for p in np.isin(range(len(self)), args)]]\n",
    "    def shuffle(self):\n",
    "        return self[np.random.choice(range(len(self)), len(self))]\n",
    "    def split(self, n_out = None, p_out = None, label = False):\n",
    "        if not label:\n",
    "            if not n_out:\n",
    "                n_out = int(np.round(p_out * len(self)))\n",
    "            out = np.random.choice(range(len(self)), n_out)\n",
    "            return self.remove([out]), self[out]\n",
    "        else:\n",
    "            d_in, d_out = zip(*[self.filter(label).split(n_out, p_out, False) for label, num in self.count()])\n",
    "            return MyDataSet.merge(d_in).shuffle(), MyDataSet.merge(d_out).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DataSet of 2048 records with 40 labels>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in a single dataset\n",
    "DS0 = MyDataSet.from_h5_file('ply_data_train0.h5')\n",
    "DS0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of records: 2048\t\tNum of unique labels: 40\n",
      "Unique labels and their frequencies:\n",
      "(8, 191) (0, 138) (30, 138) (22, 110) (4, 106) (37, 99) (2, 94) (33, 77) (35, 69) (36, 64) (5, 62) (26, 61) (21, 55) (7, 44) (23, 44) (14, 42) (3, 41) (25, 41) (31, 41) (12, 40) (16, 36) (15, 35) (17, 33) (11, 32) (18, 32) (20, 29) (9, 28) (34, 28) (19, 27) (28, 24) (38, 24) (27, 23) (29, 23) (32, 23) (24, 21) (1, 19) (13, 16) (39, 16) (6, 14) (10, 8)\n"
     ]
    }
   ],
   "source": [
    "# Summary of this dataset\n",
    "DS0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DataSet of 2048 records with 40 labels>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in another dataset\n",
    "DS1 = MyDataSet.from_h5_file('ply_data_train1.h5')\n",
    "DS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DataSet of 4096 records with 40 labels>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can feel free to combine datasets\n",
    "DS_com1 = DS0 + DS1\n",
    "DS_com1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DataSet of 4096 records with 40 labels>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to combine datasets\n",
    "DS_com2 = MyDataSet.merge([DS0, DS1])\n",
    "DS_com2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DataSet of 9840 records with 40 labels>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can even combine the datasets from reading files\n",
    "DS_full = MyDataSet.from_h5_files([f'ply_data_train{i}.h5' for i in range(5)])\n",
    "DS_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of records: 9840\t\tNum of unique labels: 40\n",
      "Unique labels and their frequencies:\n",
      "(8, 889) (30, 680) (0, 625) (4, 572) (2, 515) (37, 475) (22, 465) (33, 392) (35, 344) (5, 335) (21, 284) (36, 267) (26, 239) (25, 231) (12, 200) (14, 200) (23, 200) (7, 197) (3, 173) (16, 171) (9, 167) (34, 163) (17, 155) (15, 149) (20, 149) (18, 145) (11, 137) (29, 128) (19, 124) (31, 124) (28, 115) (13, 109) (1, 106) (27, 104) (39, 103) (32, 90) (24, 88) (38, 87) (10, 79) (6, 64)\n"
     ]
    }
   ],
   "source": [
    "# Let's see how the full dataset looks like\n",
    "DS_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30],\n",
       "       [27],\n",
       "       [30],\n",
       "       ...,\n",
       "       [35],\n",
       "       [ 7],\n",
       "       [ 8]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can obtain labels or data using bracket []\n",
    "DS_full['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DataSet of 7 records with 7 labels>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also get observations using bracket and index\n",
    "DS_full[[1,4,8,10,13,15,19]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DataSet of 4920 records with 40 labels>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or, with bracket and boolean values\n",
    "DS_full[[i % 2 == 0 for i in range(len(DS_full))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DataSet of 9833 records with 40 labels>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to drop out some observations, you can do this.\n",
    "# Don't be afraid, this is done out of place.\n",
    "# That means, it will generate a new dataset with observations removed,\n",
    "# not affecting the old dataset\n",
    "DS_full.remove([[1,4,8,10,13,15,19]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DataSet of 4920 records with 40 labels>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boolean values also work\n",
    "DS_full.remove([[i % 2 == 0 for i in range(len(DS_full))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are really afraid of using remove, you can save the old one in advance.\n",
    "DS_backup = DS_full.duplicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DataSet of 731 records with 2 labels>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To filter out only observations with labels 0 and 1, you can do:\n",
    "DS_L01 = DS_full.filter([0, 1])\n",
    "DS_L01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 625),\n",
       " (1, 106),\n",
       " (2, 515),\n",
       " (3, 173),\n",
       " (4, 572),\n",
       " (5, 335),\n",
       " (6, 64),\n",
       " (7, 197),\n",
       " (8, 889),\n",
       " (9, 167),\n",
       " (10, 79),\n",
       " (11, 137),\n",
       " (12, 200),\n",
       " (13, 109),\n",
       " (14, 200),\n",
       " (15, 149),\n",
       " (16, 171),\n",
       " (17, 155),\n",
       " (18, 145),\n",
       " (19, 124),\n",
       " (20, 149),\n",
       " (21, 284),\n",
       " (22, 465),\n",
       " (23, 200),\n",
       " (24, 88),\n",
       " (25, 231),\n",
       " (26, 239),\n",
       " (27, 104),\n",
       " (28, 115),\n",
       " (29, 128),\n",
       " (30, 680),\n",
       " (31, 124),\n",
       " (32, 90),\n",
       " (33, 392),\n",
       " (34, 163),\n",
       " (35, 344),\n",
       " (36, 267),\n",
       " (37, 475),\n",
       " (38, 87),\n",
       " (39, 103)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To relabel, just use a dictionary with {old: new} as parameter\n",
    "# Let's swap label 0 and label 1\n",
    "# Before swapping,\n",
    "DS_full.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 106),\n",
       " (1, 625),\n",
       " (2, 515),\n",
       " (3, 173),\n",
       " (4, 572),\n",
       " (5, 335),\n",
       " (6, 64),\n",
       " (7, 197),\n",
       " (8, 889),\n",
       " (9, 167),\n",
       " (10, 79),\n",
       " (11, 137),\n",
       " (12, 200),\n",
       " (13, 109),\n",
       " (14, 200),\n",
       " (15, 149),\n",
       " (16, 171),\n",
       " (17, 155),\n",
       " (18, 145),\n",
       " (19, 124),\n",
       " (20, 149),\n",
       " (21, 284),\n",
       " (22, 465),\n",
       " (23, 200),\n",
       " (24, 88),\n",
       " (25, 231),\n",
       " (26, 239),\n",
       " (27, 104),\n",
       " (28, 115),\n",
       " (29, 128),\n",
       " (30, 680),\n",
       " (31, 124),\n",
       " (32, 90),\n",
       " (33, 392),\n",
       " (34, 163),\n",
       " (35, 344),\n",
       " (36, 267),\n",
       " (37, 475),\n",
       " (38, 87),\n",
       " (39, 103)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After swapping\n",
    "DS_full.relabel({0: 1, 1: 0}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 625),\n",
       " (1, 106),\n",
       " (2, 515),\n",
       " (3, 173),\n",
       " (4, 572),\n",
       " (5, 335),\n",
       " (6, 64),\n",
       " (7, 197),\n",
       " (8, 889),\n",
       " (9, 167),\n",
       " (10, 79),\n",
       " (11, 137),\n",
       " (12, 200),\n",
       " (13, 109),\n",
       " (14, 200),\n",
       " (15, 149),\n",
       " (16, 171),\n",
       " (17, 155),\n",
       " (18, 145),\n",
       " (19, 124),\n",
       " (20, 149),\n",
       " (21, 284),\n",
       " (22, 465),\n",
       " (23, 200),\n",
       " (24, 88),\n",
       " (25, 231),\n",
       " (26, 239),\n",
       " (27, 104),\n",
       " (28, 115),\n",
       " (29, 128),\n",
       " (30, 680),\n",
       " (31, 124),\n",
       " (32, 90),\n",
       " (33, 392),\n",
       " (34, 163),\n",
       " (35, 344),\n",
       " (36, 267),\n",
       " (37, 475),\n",
       " (38, 87),\n",
       " (39, 103)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This modification does not change the original dataset.\n",
    "DS_full.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle is nice\n",
    "DS_full = DS_full.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<DataSet of 8893 records with 40 labels>,\n",
       " <DataSet of 1000 records with 40 labels>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's make some split between training data and test data\n",
    "# Sample 1000 out as test data\n",
    "DS_full.split(n_out = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<DataSet of 8913 records with 40 labels>,\n",
       " <DataSet of 984 records with 40 labels>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 10% out as test data\n",
    "DS_full.split(p_out = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<DataSet of 6793 records with 40 labels>,\n",
       " <DataSet of 4000 records with 40 labels>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 100 out in each label as test data\n",
    "DS_full.split(n_out = 100, label = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<DataSet of 8899 records with 40 labels>,\n",
       " <DataSet of 986 records with 40 labels>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 10% out in each label as test data\n",
    "DS_full.split(p_out = 0.1, label = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<DataSet of 9740 records with 40 labels>,\n",
       " <DataSet of 100 records with 34 labels>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you use n_out and p_out together, p.out will be ignored\n",
    "DS_full.split(n_out = 100, p_out = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DataSet of 1000 records with 40 labels>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's play with a small dataset with 1000 observations.\n",
    "DS_play = DS_full.shuffle()[:1000]\n",
    "DS_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it back to h5 file\n",
    "DS_play.to_h5_file('play_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also save back without the extension\n",
    "DS_play.to_h5_file('play_test_without_extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can limit the maximum size of each file\n",
    "DS_play.to_h5_file('play_max_size.h5', max_size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
